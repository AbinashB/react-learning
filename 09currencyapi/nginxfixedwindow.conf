events {
    worker_connections 1024;
}

http {
    # Custom log format to show which backend handled the request
    log_format upstream '$remote_addr - $remote_user [$time_local] '
                        '"$request" $status $body_bytes_sent '
                        '"$http_referer" "$http_user_agent" '
                        'upstream: $upstream_addr';
    
    # ============================================
    # RATE LIMITING - Fixed Window
    # ============================================
    # Define rate limit zone: 10 requests per minute per IP
    # Zone "api_limit" stores client IPs in 10MB of memory
    # Rate: 10r/m = 10 requests per minute (Fixed Window)
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/m;
    
    # Define rate limit for general endpoints (less restrictive)
    limit_req_zone $binary_remote_addr zone=general_limit:10m rate=30r/m;
    
    # Status code to return when rate limit is exceeded
    limit_req_status 429;
    
    # Define upstream servers (your API instances)
    upstream currency_api_backend {
        # Load balancing method: round-robin (default)
        # Other options: least_conn, ip_hash, random
        
        server currency-api-1:8080;
        server currency-api-2:8080;
        
        # Optional: health check settings
        # server currency-api-1:8080 max_fails=3 fail_timeout=30s;
        # server currency-api-2:8080 max_fails=3 fail_timeout=30s;
    }

    # Server configuration
    server {
        listen 80;
        server_name localhost;

        # Add custom header to identify which backend handled the request
        add_header X-Upstream-Server $upstream_addr always;
        
        # Add rate limit headers to responses
        add_header X-RateLimit-Limit "10 per minute" always;
        
        # Logging with custom format showing upstream server
        access_log /var/log/nginx/access.log upstream;
        error_log /var/log/nginx/error.log;

        # Custom error page for rate limit exceeded (429)
        error_page 429 = @rate_limit_exceeded;
        
        location @rate_limit_exceeded {
            default_type application/json;
            add_header Content-Type application/json always;
            add_header X-RateLimit-Limit "10 per minute" always;
            add_header Retry-After "60" always;
            return 429 '{"error":"Rate limit exceeded","message":"Too many requests. Maximum 10 requests per minute allowed.","status":429,"retry_after":"60 seconds"}';
        }

        # API endpoints with strict rate limiting (10 requests per minute)
        location /api/ {
            # Apply rate limiting: max 10 requests per minute
            # burst=5 allows temporary burst of 5 extra requests
            # nodelay processes burst requests immediately
            limit_req zone=api_limit burst=5 nodelay;
            
            proxy_pass http://currency_api_backend;
            
            # Forward original headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Timeout settings
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
            
            # Buffering settings
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
            proxy_busy_buffers_size 8k;
        }
        
        # Root endpoint with general rate limiting (30 requests per minute)
        location = / {
            limit_req zone=general_limit burst=10 nodelay;
            proxy_pass http://currency_api_backend;
            
            # Forward original headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Health check endpoint for the load balancer itself
        location /nginx-health {
            access_log off;
            return 200 "Nginx Load Balancer is healthy\n";
            add_header Content-Type text/plain;
        }
    }
}

